mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- trainCapAve - mean(trainCapAve)/sd(trainCapAve)
mean(trainCapAveS)
hist(trainCapAveS,main="",xlabl="ave. capital run length")
hist(trainCapAveS,main="",xlab="ave. capital run length")
hist(trainCapAveS,main="",xlab="ave. capital run length")
mean(trainCapAveS)
sd(trainCapAveS)
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testing <- spam[-inTrain,]
testCapAve <- testing$capitalAve
testCapAveS <- (testing$capitalAve - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preOj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preOj,training[,58])$capitalAve
trainCapAveS <- predict(preOj,training[-,58])$capitalAve
trainCapAveS <- predict(preOj,training[,-58])$capitalAve
mean(trainCapAve)
sd(trainCapAve)
testCapAveS <- predict(preOj,testing[,-58])$capitalAve
mean(testCapAveS)
mean(trainCapAveS)
set.seed(32343)
preObj <- preProcess(training[,58],mehtod=c("BoxCox"))
preObj <- preProcess(training[,-58],mehtod=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2))
hist(trainCapAveS)
qqnorm(trainCapAveS)
set.seed(13343)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
installed.packages("RANN")
library(RANN)
install.packages("RANN")
library(RANN)
capAve <- predict(preObj,training[,-58])$capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve-capAveTruth)
quantile((capAve-capAveTruth))[selectNA]
quantile((capAve-capAveTruth)[selectNA])
quantile((capAve-capAveTruth)[!selectNA])
spam$capitalAveSq <- spam$capitalAve^2
spam$capitalAveSq <- spam$capitalAve^2
table(training$jobclass)
library(splines)
bsBasis <- bs(training$age,df=3)
data("faithful")
inTrian <- createDataPartition(y=faithful$waiting,p=0.5,list=FALSE)
trainFaith <- faithful[inTrain,]
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFath$eruptions,pch=19,col="blue",xlab="waiting",ylab="Duration")
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="waiting",ylab="Duration")
lm1 <- lm(eruptions~waiting,data=trainFaith)
summary(lm1)
summary(lm1)
lines(trainFaith$waiting,lm1$fitted.values,lwd=3)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blu",xlab="Waiting",ylab="Duration")
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,lm1$fitted,lwd=3)
lines(trainFaith$waiting,lm1$fitted.values,lwd=3)
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
head(lm1$fitted.values)
lines(trainFaith$waiting,lm1$fitted.values,lwd=3)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
trainFaith$waiting
coef(lm1)
coef(lm1)[1]
coef(lm1)[1]+coef(lm1[2])*80
coef(lm1)[1]+coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
library(ISLR)
install.packages(ISLR)
install.packages("ISLR")
library(ISLR)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(caret)
data("Wage")
Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F)
training <- Wage[inTrain,]
testing = Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,data=training,colour=jobclass)
qplot(age,wage,data=training,colour=education)
modFit <- train(wage !age + jobclass + education, method = "lm", data= training)
modFit <- train(wage ~age + jobclass + education, method = "lm", data= training)
finMod <- modFit$finalModel
print(modFit)
modFit <- train(wage ~age + as.Factor(jobclass) + as.Factor(education), method = "lm", data= training)
modFit <- train(wage ~age + as.factor(jobclass) + as.factor(education), method = "lm", data= training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col"#00000010")
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
data(AlzheimerDisease)
head(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
library(ggplot2)
library(RANN)
data(AlzheimerDisease)
head(AlzheimerDiseasae)
str(AlzheimerDisease)
data(AlzheimerDisease)
head(AlzheimerDisease)
data(AlzheimerDisease)
data(AlzheimerDisease)
View(predictors)
str(predictors)
names(predicotors)
names(predictors)
adData <- data.frame(diagnosis,predictors)
head(adData)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
plot(CompressiveStrenght,data=training)
plot(CompressiveStrength,data=training)
plot(training$CompressiveStrength)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
names <- colnames(concrete)
names <- names[-length(names)]
faturePlot(x = training,[,names],y=training$CompressiveStrength,plot="pairs")
faturePlot(x = training[,names],y=training$CompressiveStrength,plot="pairs")
featurePlot(x = training[,names],y=training$CompressiveStrength,plot="pairs")
index <- seq_along(1:nrow(training))
ttplot(data=training, aes(x=index,y=CompressiveStrength))+ geom_point()+theme_bw()
ggplot(data=training, aes(x=index,y=CompressiveStrength))+ geom_point()+theme_bw()
qplot(training$CompressiveStrength)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength)
plot(training$CompressiveStrength,color=cut2(training$Cement,g=breaks))
plot(training$CompressiveStrength,color=cut2(training$Cement,g=10))
plot(training$CompressiveStrength,colour=cut2(training$Cement,g=10))
suppressMessages(library(dplyr))
suppressMessages(library(Hmisc))
suppressMessages(library(gridExtra))
training <- mutate(training, index=1:nrow(training))
cutIndex <- cut2(training$index, g=10)
breaks <- 10
gplot(training$CompressiveStrength,colour=cut2(training$Cement,g=10))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=breaks))
names(training)
qplot(index, CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$BlastFurnaceSlag, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Age, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Age, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Age, g=breaks))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
IdxCol_IL <- grep("^IL", names(training))
train_IL <- training[,IdxCol_IL]
test_IL <- testing[,IdxCol_IL]
preproc <- preProcess(train_IL, method="pca", thresh=0.9)
preproc$numComp
train_IL <- training[,IdxCol_IL]
test_IL <- testing[,IdxCol_IL]
preproc <- preProcess(train_IL, method="pca", thresh=0.9)
?preProcess
train_IL <- training[,IdxCol_IL]
test_IL <- testing[,IdxCol_IL]
preproc <- preProcess(train_IL, method="pca", thresh=0.9)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3430)
suppressMessages(library(dplyr))
IdxCol_IL <- grep("^IL", names(testing))
names_IL <- names(testing[,IdxCol_IL])
newcols <- c(names_IL,"diagnosis")
new_testing <- testing [,newcols]
new_training <- training[,newcols]
# Model 1 : predictors as they are, without PCA
model_without_PCA <- train(diagnosis~., data=new_training,   preProcess=c("center","scale"),method="glm")
model_result_without_PCA <- confusionMatrix(new_testing$diagnosis,predict(model_without_PCA,subset(new_testing, select = -c(diagnosis))))
model_result_without_PCA
data("iris")
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=F)
train <- iris[inTrain,]
test <- iris[-inTrain,]
dim(train)
dim(test)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
head(train)
qplot(Petal.Width,Sepal.Width,colour=Species,data=train)
modFit <- train(Species ~ ., method="rpart",data=training)
modFit <- train(Species ~ ., method="rpart",data=train)
library(e1071)
install.packages("e1071")
library(e1071)
modFit <- train(Species ~ ., method="rpart",data=train)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,use.n=T,all=T,cex=.8)
install.packages("rattle")
library(rattle)
predict(modFit,newdata=testing)
predict(modFit,newdata=test)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("ozone")
ozone >- ozone[order(ozone$ozone,)]
ozone >- ozone[order(ozone$ozone),]
head(ozone)
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
for(i:10){
ss <- sample(1:dim(ozone)[1],replace=T)
}
for(i:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,];ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,];ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,];ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:55,ll[i,],col="grey",lwd=2)}
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
str(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.75)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.75,list=F)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrian,]
test <- segmentationOriginal[-inTrain,]
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.60,list=F)
train <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Class ~.,method = "rpart,data=train")
modFit <- train(Class ~.,method = "rpart",data=train)
print(modFit$finalModel)
install.packages("rattle")
library(rattle)
install.packages("rattle")
library(rattle)
install.packages("Cairo Device")
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("oliv")
install.packages("olive")
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ggplot2)
setwd("/Users/mickey/Documents/GitHub/practical-machine-learning")
if (!file.exists("train.csv")){
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL, "train.csv", method="curl")
}
if (!file.exists("test.csv")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL, "test.csv", method="curl")
}
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test [-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
mod2 <- randomForest(classe~.,data=sub_train,method="class")
pred2 <- predict(mod2,sub_test,type="class")
confusionMatrix(pred2,sub_test$classe)
predictfinal <- predict(mod2, test, type="class")
predictfinal
mod2 <- randomForest(classe~.,data=sub_train,method="class")
pred2 <- predict(mod2,sub_test,type="class")
confusionMatrix(pred2,sub_test$classe)
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test [-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,sub_test,type="class")
confusionMatrix(pred1, sub_test$classe)
confusionMatrix(pred1, sub_test$classe)
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test [-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ggplot2)
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,sub_test,type="class")
pred1 <- predict(mod1,data=sub_test,type="class")
confusionMatrix(pred1, sub_test$classe)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test[-sub,]
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test[-sub,]
if (!file.exists("train.csv")){
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL, "train.csv", method="curl")
}
if (!file.exists("test.csv")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL, "test.csv", method="curl")
}
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
dim(train)
dim(test)
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
dim(train)
dim(test)
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test[-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
dim(sub_test)
dim(sub_train)
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
confusionMatrix(pred1, sub_test$classe)
str(sub_train)
str(sub_test)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ggplot2)
setwd("/Users/mickey/Documents/GitHub/practical-machine-learning")
if (!file.exists("train.csv")){
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL, "train.csv", method="curl")
}
if (!file.exists("test.csv")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL, "test.csv", method="curl")
}
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- test[-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
identical (levels(sub_test), levels(sub_train))
str(sub_test)
summary(sub_train$classe)
str(sub_train$classe)
str(train$classe)
str(test$classe)
View(test)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- train[-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
mod2 <- randomForest(classe~.,data=sub_train,method="class")
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- train[-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
rpart.plot(mod1,main="Classification Tree", extra=102,under=T,faclen=0)
confusionMatrix(pred1, sub_test$classe)
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(tidyverse)
library(ggplot2)
setwd("/Users/mickey/Documents/GitHub/practical-machine-learning")
if (!file.exists("train.csv")){
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileURL, "train.csv", method="curl")
}
if (!file.exists("test.csv")) {
fileURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURL, "test.csv", method="curl")
}
train <- read.csv("train.csv",na.strings=c("NA","DIV/0!",""))
test <- read.csv("test.csv",na.strings=c("NA","DIV/0!",""))
train<- train[,colSums(is.na(train)) == 0] %>% select(-c(1:7))
test <- test[,colSums(is.na(test)) == 0] %>% select(-c(1:7))
set.seed(24)
sub <- createDataPartition(y=train$classe,p=0.75,list=F)
sub_train <- train[sub,]
sub_test <- train[-sub,]
mod1 <- rpart(classe~.,data=sub_train,method="class")
pred1 <- predict(mod1,data=sub_test,type="class")
confusionMatrix(pred1, sub_test$classe)
confusionMatrix(pred1, sub_test$classe)
length(sub_test$classe)
length(sub_train$classe)
length(pred1)
confusionMatrix(pred1, sub_train$classe)
confusionMatrix(pred1, sub_test$classe)
mod2 <- randomForest(classe~.,data=sub_train,method="class")
pred2 <- predict(mod2,data=sub_test,type="class")
confusionMatrix(pred2,sub_test$classe)
